{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shirleyzz/cap5610_machineleanrning/blob/master/HW3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "YxtoTwJz71fi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "83bbdb98-e9e7-4435-f25a-4fa1bcf1b578"
      },
      "cell_type": "code",
      "source": [
        "#Load the training and test data using Keras\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "from keras import backend as K\n",
        "import keras\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "bKebYiAev5mF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(x_train_origin, y_train_origin),(x_test_origin, y_test_origin) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hVWJ8ysK-CmP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = x_train_origin.reshape((60000, 28 * 28))\n",
        "x_train = x_train_origin.astype('float32') / 255\n",
        "\n",
        "x_test = x_test_origin.reshape((10000, 28 * 28))\n",
        "x_test = x_test_origin.astype('float32') / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8ux2HdzI2GLm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], -1)\n",
        "x_test = x_test.reshape(x_test.shape[0], -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jlFgDMdB-sHg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Each of the ten classifiers has an input layer consisting of 28 x 28 input neurons and an output layer consisting of a single output neuron.\n"
      ]
    },
    {
      "metadata": {
        "id": "LVDgI6FHHokM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#calculate cross entropy\n",
        "def softmax(scores):\n",
        "  exp = np.exp(scores)\n",
        "  sum_exp = np.sum(np.exp(scores), axis=1, keepdims=True)\n",
        "  softmax = exp / sum_exp\n",
        "  return softmax\n",
        "def compute_scores(w,b,X):\n",
        "  #print(X.shape)\n",
        "  return np.dot(X,w.T) + b\n",
        "def cross_entropy(X, Y, scores):\n",
        "  m = X.shape[0]\n",
        "  loss = - (1 / m) * np.sum(Y * np.log(scores))\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yPHrzJsge085",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#tranforms vector Y of labels to one-hot encoded matrix\n",
        "def one_hot(X, Y, n_classes=10):\n",
        "  m = X.shape[0]\n",
        "  one_hot = np.zeros((m, n_classes))\n",
        "  one_hot[np.arange(m), Y.T] = 1\n",
        "  return one_hot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "THW9q3YPc61M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def initialize_params_with_zeros(n_classes, n_features):\n",
        "  w = np.random.rand(n_classes, n_features)\n",
        "  b = np.zeros((1, n_classes))\n",
        "  return w,b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TXSC79lMdoRk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# predict\n",
        "def predict(w,b,X):\n",
        "  scores = compute_scores(w,b,X)\n",
        "  probs = softmax(scores)\n",
        "  return np.argmax(probs, axis=1)[:, np.newaxis]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oFkjcXsbgZie",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(X_train, Y_train, n_iters=10, learning_rate=0.1,n_classes = 10):\n",
        "  n_samples,n_features = X_train.shape\n",
        "  w, b = initialize_params_with_zeros(n_classes,n_features)\n",
        "  all_losses = []\n",
        "  theta = np.random.randn(n_samples,1)\n",
        "  for item in range(n_iters):\n",
        "    cost = 0.0\n",
        "    for i in range(n_samples):\n",
        "      rand_ind = np.random.randint(0,n_samples)\n",
        "      X_i = X_train[rand_ind,:].reshape(1,n_features)\n",
        "      Y_i = Y_train[rand_ind].reshape(1,1)\n",
        "      y_one_hot = one_hot(X_i,Y_i)\n",
        "      scores = compute_scores(w,b,X_i)\n",
        "      probs = softmax(scores)\n",
        "      loss = cross_entropy(X_i,y_one_hot, probs)\n",
        "      dw = (1 / n_samples) * np.dot(X_i.T, (probs - y_one_hot))\n",
        "      db = (1 / n_samples) * np.sum(probs - y_one_hot, axis=0)\n",
        "      w = w - learning_rate * dw.T\n",
        "      b = b - learning_rate * db\n",
        "    all_losses.append(loss)\n",
        "    print(f'Iteration number: {item}, loss: {np.round(loss, 4)}')\n",
        "  return w, b, all_losses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CWVaj0B15-4p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# w, b, loss = train(x_train, y_train_origin, learning_rate=0.01, n_iters=1, n_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ea0GUNWG6CD5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Y_pred_test = predict(w, b, x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ymljVaDO6TE4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Y_pred_test[:,0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zZ4QPv-H7F7i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# y_test_origin"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bMXjHZvM6oyO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# flag = np.where(Y_pred_test[:,0] == y_test_origin, 1, 0)\n",
        "# flag"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CjMU4CPP6MIv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# print(\"train accuracy: {} %\".format(100 - (np.where(Y_pred_test == y_test_origin) * 100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EkLkv4o36UZp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# y_test_origin"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "dkyRZGpS5mza",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model(X_train, Y_train, X_test, Y_test, num_iters, learning_rate,n_classes):\n",
        "  w, b, loss = train(X_train, Y_train, num_iters, learning_rate, n_classes)\n",
        "  # Predict test/train set examples \n",
        "  Y_pred_test = predict(w, b, X_test)\n",
        "  Y_pred_train = predict(w, b, X_train)\n",
        "\n",
        "# Print train/test Errors\n",
        "  print(\"\")\n",
        "  print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_pred_train - Y_train)) * 100))\n",
        "  print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_pred_test - Y_test)) * 100))\n",
        "  repr('train accuracy')\n",
        "  \n",
        "  d = {\"costs\": costs,\n",
        "         \"Y_pred_test\": Y_pred_test, \n",
        "         \"Y_pred_train\" : Y_pred_train, \n",
        "         \"w\" : w, \n",
        "         \"b\" : b,\n",
        "         \"learning_rate\" : learning_rate,\n",
        "         \"num_iters\": num_iters}\n",
        "    \n",
        "  return d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "smB0hnnT1moN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ee360648-b9c4-4195-cd1e-b51866209635"
      },
      "cell_type": "code",
      "source": [
        "d = model(x_train, y_train_origin, x_test, y_test_origin, num_iters=20, learning_rate=0.01,n_classes=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration number: 0, loss: 4.2281\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nsWFAbpYeGEd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}