{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shirleyzz/cap5610_machineleanrning/blob/master/HW3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "YxtoTwJz71fi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Load the training and test data using Keras\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "from keras import backend as K\n",
        "import keras\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bKebYiAev5mF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(x_train_origin, y_train_origin),(x_test_origin, y_test_origin) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hVWJ8ysK-CmP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = x_train_origin.reshape((60000, 28 * 28))\n",
        "x_train = x_train_origin.astype('float32') / 255\n",
        "\n",
        "x_test = x_test_origin.reshape((10000, 28 * 28))\n",
        "x_test = x_test_origin.astype('float32') / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8ux2HdzI2GLm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], -1)\n",
        "x_test = x_test.reshape(x_test.shape[0], -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jlFgDMdB-sHg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Each of the ten classifiers has an input layer consisting of 28 x 28 input neurons and an output layer consisting of a single output neuron.\n"
      ]
    },
    {
      "metadata": {
        "id": "LVDgI6FHHokM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#calculate cross entropy\n",
        "def softmax(scores):\n",
        "  exp = np.exp(scores)\n",
        "  sum_exp = np.sum(np.exp(scores), axis=1, keepdims=True)\n",
        "  softmax = exp / sum_exp\n",
        "  return softmax\n",
        "def compute_scores(w,b,X):\n",
        "  #print(X.shape)\n",
        "  return np.dot(X,w.T) + b\n",
        "def cross_entropy(X, Y, scores):\n",
        "  m = X.shape[0]\n",
        "  loss = - (1 / m) * np.sum(Y * np.log(scores))\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yPHrzJsge085",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#tranforms vector Y of labels to one-hot encoded matrix\n",
        "def one_hot(X, Y, n_classes=10):\n",
        "  m = X.shape[0]\n",
        "  one_hot = np.zeros((m, n_classes))\n",
        "  #print(one_hot.shape)\n",
        "  one_hot[np.arange(m), Y.T] = 1\n",
        "  return one_hot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "THW9q3YPc61M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def initialize_params_with_zeros(n_classes, n_features):\n",
        "  w = np.random.rand(n_classes, n_features)\n",
        "  b = np.zeros((1, n_classes))\n",
        "  return w,b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TXSC79lMdoRk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# predict\n",
        "def predict(w,b,X):\n",
        "  scores = compute_scores(w,b,X)\n",
        "  probs = softmax(scores)\n",
        "  return np.argmax(probs, axis=1)[:, np.newaxis]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oFkjcXsbgZie",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(X_train, Y_train, X_test, Y_test, n_iters=10, learning_rate=0.1,n_classes = 10):\n",
        "  \n",
        "  n_samples,n_features = X_train.shape\n",
        "  \n",
        "  w, b = initialize_params_with_zeros(n_classes,n_features)\n",
        "       \n",
        "  all_losses = []\n",
        "  for i in range(n_iters):\n",
        "    scores = compute_scores(w,b,X_train)\n",
        "    probs = softmax(scores)\n",
        "    y_predict = np.argmax(probs, axis=1)[:, np.newaxis]\n",
        "    y_one_hot = one_hot(X_train,Y_train)\n",
        "    loss = cross_entropy(X_train,y_one_hot, probs)\n",
        "    all_losses.append(loss)\n",
        "    dw = (1 / n_samples) * np.dot(X_train.T, (probs - y_one_hot))\n",
        "    db = (1 / n_samples) * np.sum(probs - y_one_hot, axis=0)\n",
        "    w = w - learning_rate * dw.T\n",
        "    b = b - learning_rate * db\n",
        "    print(f'Iteration number: {i}, loss: {np.round(loss, 4)}')\n",
        "#     if i % 100 == 0:\n",
        "#       print(f'Iteration number: {i}, loss: {np.round(loss, 4)}')\n",
        "  return w, b, all_losses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iJnqAaX3jB4O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1540
        },
        "outputId": "152c9450-a9a6-464c-9c4e-04a7aa4d6f14"
      },
      "cell_type": "code",
      "source": [
        "w_trained, b_trained, loss = train(x_train, y_train_origin, x_test, y_test_origin, learning_rate=0.1, n_iters=800, n_classes=10)"
      ],
      "execution_count": 333,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration number: 0, loss: 4.4455\n",
            "Iteration number: 1, loss: 4.1023\n",
            "Iteration number: 2, loss: 3.863\n",
            "Iteration number: 3, loss: 3.6637\n",
            "Iteration number: 4, loss: 3.4893\n",
            "Iteration number: 5, loss: 3.3334\n",
            "Iteration number: 6, loss: 3.1921\n",
            "Iteration number: 7, loss: 3.0629\n",
            "Iteration number: 8, loss: 2.9443\n",
            "Iteration number: 9, loss: 2.8355\n",
            "Iteration number: 10, loss: 2.7358\n",
            "Iteration number: 11, loss: 2.6442\n",
            "Iteration number: 12, loss: 2.5599\n",
            "Iteration number: 13, loss: 2.4818\n",
            "Iteration number: 14, loss: 2.4089\n",
            "Iteration number: 15, loss: 2.3406\n",
            "Iteration number: 16, loss: 2.276\n",
            "Iteration number: 17, loss: 2.215\n",
            "Iteration number: 18, loss: 2.157\n",
            "Iteration number: 19, loss: 2.1019\n",
            "Iteration number: 20, loss: 2.0496\n",
            "Iteration number: 21, loss: 1.9998\n",
            "Iteration number: 22, loss: 1.9524\n",
            "Iteration number: 23, loss: 1.9072\n",
            "Iteration number: 24, loss: 1.8643\n",
            "Iteration number: 25, loss: 1.8234\n",
            "Iteration number: 26, loss: 1.7845\n",
            "Iteration number: 27, loss: 1.7474\n",
            "Iteration number: 28, loss: 1.712\n",
            "Iteration number: 29, loss: 1.6783\n",
            "Iteration number: 30, loss: 1.6461\n",
            "Iteration number: 31, loss: 1.6154\n",
            "Iteration number: 32, loss: 1.586\n",
            "Iteration number: 33, loss: 1.558\n",
            "Iteration number: 34, loss: 1.5312\n",
            "Iteration number: 35, loss: 1.5055\n",
            "Iteration number: 36, loss: 1.481\n",
            "Iteration number: 37, loss: 1.4575\n",
            "Iteration number: 38, loss: 1.4349\n",
            "Iteration number: 39, loss: 1.4132\n",
            "Iteration number: 40, loss: 1.3925\n",
            "Iteration number: 41, loss: 1.3725\n",
            "Iteration number: 42, loss: 1.3533\n",
            "Iteration number: 43, loss: 1.3349\n",
            "Iteration number: 44, loss: 1.3171\n",
            "Iteration number: 45, loss: 1.3\n",
            "Iteration number: 46, loss: 1.2835\n",
            "Iteration number: 47, loss: 1.2676\n",
            "Iteration number: 48, loss: 1.2523\n",
            "Iteration number: 49, loss: 1.2375\n",
            "Iteration number: 50, loss: 1.2232\n",
            "Iteration number: 51, loss: 1.2093\n",
            "Iteration number: 52, loss: 1.196\n",
            "Iteration number: 53, loss: 1.183\n",
            "Iteration number: 54, loss: 1.1705\n",
            "Iteration number: 55, loss: 1.1584\n",
            "Iteration number: 56, loss: 1.1467\n",
            "Iteration number: 57, loss: 1.1353\n",
            "Iteration number: 58, loss: 1.1242\n",
            "Iteration number: 59, loss: 1.1135\n",
            "Iteration number: 60, loss: 1.1031\n",
            "Iteration number: 61, loss: 1.093\n",
            "Iteration number: 62, loss: 1.0832\n",
            "Iteration number: 63, loss: 1.0736\n",
            "Iteration number: 64, loss: 1.0644\n",
            "Iteration number: 65, loss: 1.0553\n",
            "Iteration number: 66, loss: 1.0466\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-333-0bf2d87e5f06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw_trained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_trained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_origin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_origin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m800\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-332-d01b53579b9b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(X_train, Y_train, X_test, Y_test, n_iters, learning_rate, n_classes)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mall_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0my_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-328-92e9eff6ea42>\u001b[0m in \u001b[0;36mcompute_scores\u001b[0;34m(w, b, X)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;31m#print(X.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "nsWFAbpYeGEd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}